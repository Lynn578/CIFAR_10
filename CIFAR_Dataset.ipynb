{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDbrYnqd7uL-"
   },
   "source": [
    "### Introduction to the CIFAR Dataset\n",
    "\n",
    "The **CIFAR (Canadian Institute For Advanced Research)** dataset is one of the most well-known and widely used datasets in the field of computer vision and machine learning. Developed by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton, CIFAR datasets provide a large collection of labeled images that are used for training, validating, and testing machine learning models, particularly for image classification tasks.\n",
    "\n",
    "#### CIFAR-10 Dataset\n",
    "\n",
    "**CIFAR-10** is a subset of the 80 million tiny images dataset. It consists of 60,000 32x32 color images in 10 different classes, with 6,000 images per class. The dataset is divided into five training batches and one test batch, each with 10,000 images. The test batch contains exactly 1,000 randomly selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another.\n",
    "\n",
    "- **Classes**: The dataset has 10 classes, each representing a different object category:\n",
    "  1. Airplane\n",
    "  2. Automobile\n",
    "  3. Bird\n",
    "  4. Cat\n",
    "  5. Deer\n",
    "  6. Dog\n",
    "  7. Frog\n",
    "  8. Horse\n",
    "  9. Ship\n",
    "  10. Truck\n",
    "\n",
    "- **Image Dimensions**: Each image is 32x32 pixels in size and has three color channels (RGB).\n",
    "\n",
    "\n",
    "### Example Workflow with CIFAR-10\n",
    "\n",
    "1. **Data Preprocessing**: Load the CIFAR-10 dataset, normalize the pixel values to the range [0, 1], and possibly augment the data with transformations like rotations, flips, and shifts to make the model more robust.\n",
    "\n",
    "2. **Model Building**: Define a Convolutional Neural Network (CNN) architecture using a framework like TensorFlow or Keras. This typically involves multiple convolutional layers, pooling layers, and fully connected layers.\n",
    "\n",
    "3. **Model Training**: Train the model on the CIFAR-10 training set using techniques like backpropagation and optimization algorithms (e.g., Adam, SGD).\n",
    "\n",
    "4. **Evaluation**: Assess the model's performance on the test set using accuracy and other relevant metrics.\n",
    "\n",
    "5. **Inference**: Use the trained model to make predictions on new images, classifying them into one of the ten categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m54FRusmENvn"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jA3E_IE7JMtE"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR-10 data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AayssAPFJO5T"
   },
   "outputs": [],
   "source": [
    "# Normalize the images to the range of 0 to 1\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnlgkGjvJRaC"
   },
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nm2CYhU2JUry"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqVSEZfxJWuW"
   },
   "outputs": [],
   "source": [
    "# Convolutional Layer 1\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxNKO7_3JXNH"
   },
   "outputs": [],
   "source": [
    "# Convolutional Layer 2\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAJxm_JuJZ_n"
   },
   "outputs": [],
   "source": [
    "# Convolutional Layer 3\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XboQW6MHJd8O"
   },
   "outputs": [],
   "source": [
    "# Flatten the results to feed into a Dense layer\n",
    "model.add(Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LY5mi-_NJgX0"
   },
   "outputs": [],
   "source": [
    "# Fully connected layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "model.add(Dense(10, activation='softmax'))  # Output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zlalh7PJibn"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4EV7fnJJw5e",
    "outputId": "05f8af9f-7af9-48c2-c1a4-14a959f6904e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "625/625 [==============================] - 60s 93ms/step - loss: 1.8334 - accuracy: 0.3141 - val_loss: 1.5188 - val_accuracy: 0.4383\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 55s 88ms/step - loss: 1.5212 - accuracy: 0.4451 - val_loss: 1.3764 - val_accuracy: 0.5107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x787eadccdd20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIOZTj6fJypl",
    "outputId": "270b4273-c7bd-4283-9043-df0c5184cb46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 14ms/step - loss: 1.3605 - accuracy: 0.5173\n",
      "Loss: 1.3605170249938965, Accuracy: 0.517300009727478\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRY4NtOCJ2K7",
    "outputId": "2a6643ae-dd71-48ad-c6c4-f730199f0cd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step\n",
      "Prediction: 5, Actual: 3\n",
      "Prediction: 8, Actual: 8\n",
      "Prediction: 1, Actual: 8\n",
      "Prediction: 8, Actual: 0\n",
      "Prediction: 6, Actual: 6\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Show a few predictions\n",
    "import numpy as np\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Prediction: {np.argmax(predictions[i])}, Actual: {np.argmax(y_test[i])}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
